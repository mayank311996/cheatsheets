{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "disabled-township",
   "metadata": {},
   "source": [
    "# Using Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd \n",
    "\n",
    "with open('bearer_token.txt') as fp:\n",
    "    BEARER_TOKEN = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accompanied-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.twitter.com/1.1\n",
    "# https://api.twitter.com/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-submission",
   "metadata": {},
   "source": [
    "API = https://api.twitter.com/2 <br>\n",
    "Endpoint = search/tweets.json <br>\n",
    "Query = query=Tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://api.twitter.com/2/tweets/search/recent?query=Tesla')\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fantastic-disclosure",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BEARER_TOKEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-892ce4e1d858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'authorization'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf'Bearer {BEARER_TOKEN}'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m response = requests.get('https://api.twitter.com/2/tweets/search/recent?query=Tesla',\n\u001b[1;32m      3\u001b[0m                        headers=headers)\n\u001b[1;32m      4\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BEARER_TOKEN' is not defined"
     ]
    }
   ],
   "source": [
    "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
    "response = requests.get('https://api.twitter.com/2/tweets/search/recent?query=Tesla',\n",
    "                       headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-verse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
    "response = requests.get('https://api.twitter.com/2/tweets/search/recent?query=Tesla&tweet.fields=created_at,lang&max_results=100',\n",
    "                       headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-machinery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
    "params = {\n",
    "    'query': 'Tesla',\n",
    "    'tweet.fields': 'created_at,lang',\n",
    "    'max_results':100\n",
    "}\n",
    "response = requests.get('https://api.twitter.com/2/tweets/search/recent',\n",
    "                       headers=headers, params=params)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-relaxation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(response.json())[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['data'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-corrections",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = response.json()['data'][0]\n",
    "\n",
    "pd.DataFrame = ({\n",
    "    'id': [tweet['id']],\n",
    "    'text': [tweet['text']],\n",
    "    'lang': [tweet['lang']],\n",
    "    'created_at': [tweet['created_at']]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-treasury",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for tweet in response.json()['data']:\n",
    "    df = df.append(tweet, ignore_index=True)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-increase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-airline",
   "metadata": {},
   "source": [
    "# Twitter data collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd \n",
    "from datetime import datetime, timedelta \n",
    "\n",
    "with open('bearer_token.txt') as fp:\n",
    "    BEARER_TOKEN = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
    "params = {\n",
    "    'query': 'tesla',\n",
    "    'max_results': '100',\n",
    "    'tweet.fields': 'created_at, lang'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['query'] = '(tesla OR tsla OR elon musk) (lang:en)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.now()\n",
    "print(time.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta(hours=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-rental",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime('%d/%m/%Y <- date | time -> %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hour in range(24):\n",
    "    print(f'-{hour}')\n",
    "    pre60 = time - timedelta(minutes=60)\n",
    "    print(f'end\\t{time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}')\n",
    "    print(f'start\\t{pre60.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}')\n",
    "    time = pre60\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-attack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtformat = \"%Y-%m-%dT%H:%M:%SZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for hour in range(24*7 - 1):\n",
    "    pre60 = time - timedelta(minutes=60)\n",
    "    \n",
    "    params['end_time'] = time.strftime(dtformat)\n",
    "    params['start_time'] = pre60.strftime(dtformat)\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "    \n",
    "    time = pre60\n",
    "    \n",
    "    for tweet in response.json()['data']:\n",
    "        df = df.append(tweet, ignore_index=True)\n",
    "        \n",
    "    print(params['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('|', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tesla_tweets.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-simulation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-enclosure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-antique",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-preference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sharing-magnitude",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flair\n",
    "!pip install tensorflow\n",
    "!pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-bottom",
   "metadata": {},
   "source": [
    "Loading DistilBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tesla_tweets.csv', sep='|')\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = flair.data.Sentence(tweets['text'].iloc[0])\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.get_labels()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sentence.get_labels()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.get_labels()[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.get_labels()[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-shore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.labels[0].value, sentence.labels[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-dublin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "invisible-reconstruction",
   "metadata": {},
   "source": [
    "### Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "confidence = []\n",
    "\n",
    "sample = tweets.iloc[:1000]\n",
    "\n",
    "for tweet in sample['text'].to_list():\n",
    "    sentence = flair.data.Sentence(tweet)\n",
    "    sentiment_model.predict(sentence)\n",
    "    \n",
    "    sentiment.append(sentence.labels[0].value)\n",
    "    confidence.append(sentence.labels[0].score)\n",
    "    \n",
    "sample['sentiment'] = sentiment\n",
    "sample['confidence'] = confidence\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-scene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-radar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-logistics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
